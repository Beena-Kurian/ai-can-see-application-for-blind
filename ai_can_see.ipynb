{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gtts\n",
    "!pip install geocoder\n",
    "!pip install pygame\n",
    "!pip install pytesseract\n",
    "#https://digi.bib.uni-mannheim.de/tesseract/\n",
    "!pip install pywhatkit\n",
    "!pip install twilio\n",
    "!pip install opencv-python numpy\n",
    "!pip install opencv-python matplotlib tensorflow tensorflow-hub Pillow\n",
    "!pip install webcolors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from gtts import gTTS\n",
    "from datetime import datetime\n",
    "import pygame\n",
    "import geocoder\n",
    "# Additional import for camera handling\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "# import for sending email\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.image import MIMEImage\n",
    "import webbrowser\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract.exe'\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from webcolors import rgb_to_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.get_tesseract_version()\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<[OK] Ipinfo - Geocode [Kitchener, Ontario, CA]>\n"
     ]
    }
   ],
   "source": [
    "def get_current_location():\n",
    "    location = geocoder.ip('me')\n",
    "    print(location)\n",
    "get_current_location()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pygame\n",
    "pygame.mixer.init()\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "def get_weather(api_key, city):\n",
    "    base_url = \"http://api.openweathermap.org/data/2.5/weather\"\n",
    "    params = {\n",
    "        \"q\": city,\n",
    "        \"appid\": api_key,\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    weather_data = response.json()\n",
    "    return weather_data\n",
    "\n",
    "def get_current_location():\n",
    "    location = geocoder.ip('me')\n",
    "    print(location)\n",
    "    return location.city, location.latlng, location.country\n",
    "\n",
    "def generate_emergency_message():\n",
    "    # Get current location details\n",
    "    city, province, country = get_current_location()\n",
    "    \n",
    "    # Get current timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Generate emergency message\n",
    "    emergency_message = f\"aiCanSEE App: Emergency! Need help! Location: {city}, {province}, {country}. Timestamp: {timestamp}\"\n",
    "    \n",
    "    return emergency_message\n",
    "\n",
    "def play_alarm_sound():\n",
    "    # Load the alarm sound file (replace 'alarm_sound.wav' with your desired sound file)\n",
    "    pygame.mixer.music.load('./help/alarm.mp3')\n",
    "\n",
    "    # Play the alarm sound\n",
    "    pygame.mixer.music.play()\n",
    "def text_to_speech(text, output_path):\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    tts.save(output_path)\n",
    "\n",
    "def suggest_outfit(api_key):\n",
    "    city,_,_ = get_current_location()\n",
    "    weather_data = get_weather(api_key, city)\n",
    "    \n",
    "    # Check if the API call was successful\n",
    "    if weather_data.get(\"cod\") != 200:\n",
    "        return f\"Unable to retrieve weather information. Error code: {weather_data.get('cod')}\"\n",
    "    print(weather_data)\n",
    "    # Extract relevant weather information (e.g., temperature, feels_like)\n",
    "    temperature_kelvin = weather_data[\"main\"][\"temp\"]\n",
    "    feels_like_kelvin = weather_data[\"main\"][\"feels_like\"]\n",
    "\n",
    "    temperature_celsius = round(temperature_kelvin - 273.15)\n",
    "    feels_like_celsius = round(feels_like_kelvin - 273.15)\n",
    "\n",
    "    # Determine suitable outfit based on Canada's weather conditions\n",
    "    if feels_like_celsius > 25:\n",
    "        outfit_suggestion = \"You may want to wear light and breathable clothing.\"\n",
    "    elif 20 <= feels_like_celsius <= 25:\n",
    "        outfit_suggestion = \"Moderate clothing would be suitable.\"\n",
    "    elif 15 <= feels_like_celsius < 20:\n",
    "        outfit_suggestion = \"A light jacket or sweater may be comfortable.\"\n",
    "    elif 10 <= feels_like_celsius < 15:\n",
    "        outfit_suggestion = \"Consider wearing a sweater or light coat.\"\n",
    "    elif 5 <= feels_like_celsius < 10:\n",
    "        outfit_suggestion = \"A warm coat and layers would be advisable.\"\n",
    "    elif 0 <= feels_like_celsius < 5:\n",
    "        outfit_suggestion = \"Dress warmly with a winter coat and layers.\"\n",
    "    else:\n",
    "        outfit_suggestion = \"Extreme cold! Bundle up with heavy winter clothing.\"\n",
    "\n",
    "    # Format temperature information\n",
    "    temperature_str = f\"{temperature_celsius} degrees Celsius\"\n",
    "    feels_like_str = f\"{feels_like_celsius} degrees Celsius\"\n",
    "\n",
    "    # Convert the result to audio\n",
    "    text_to_speech = f\"You are currently in {city}. The current temperature is {temperature_str}, but it feels like {feels_like_str}. {outfit_suggestion}. Have a great day!\"\n",
    "    tts = gTTS(text=text_to_speech, lang='en')\n",
    "\n",
    "    # Convert the result to audio\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    # Save the audio file\n",
    "    audio_path = f\"output_{timestamp}.mp3\"\n",
    "    tts.save(audio_path)\n",
    "    return text_to_speech,audio_path\n",
    "\n",
    "def playaudio(audio_path):\n",
    "    # Play the audio\n",
    "    pygame.mixer.music.load(audio_path)\n",
    "    pygame.mixer.music.play()\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        continue\n",
    "    \n",
    "def execute_suggestion():\n",
    "    api_key = \"add_api_key_here\"\n",
    "    result,audio_path = suggest_outfit(api_key)\n",
    "    print(\"Weather\"+ result)\n",
    "    playaudio(audio_path)\n",
    "\n",
    "def capture_image(x):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    ret, frame = cap.read()\n",
    "    image_path = \"captured_image.jpg\"\n",
    "    cv2.imwrite(image_path, frame)\n",
    "    cap.release()\n",
    "\n",
    "    # Send the captured image via email\n",
    "    if x==1:\n",
    "        return image_path\n",
    "    else:\n",
    "        send_email(image_path)\n",
    "        # Perform OCR on the captured image\n",
    "        text_content = perform_ocr(image_path)\n",
    "        # Display the captured image and OCR text\n",
    "        display_captured_image(image_path, text_content)        \n",
    "\n",
    "def send_email(image_path):\n",
    "    # Set up the email server\n",
    "    server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    server.starttls()\n",
    "\n",
    "    # Log in to your email account\n",
    "    server.login(sender_email, sender_password)\n",
    "\n",
    "    # Create the email message\n",
    "    message = MIMEMultipart()\n",
    "    message['From'] = sender_email\n",
    "    message['To'] = receiver_email\n",
    "    message['Subject'] = 'Captured Image from aiCanSEE App'\n",
    "\n",
    "    # Attach the image to the email\n",
    "    with open(image_path, 'rb') as file:\n",
    "        image_data = file.read()\n",
    "        image_attachment = MIMEImage(image_data, name='captured_image.jpg')\n",
    "        message.attach(image_attachment)\n",
    "\n",
    "    # Send the email\n",
    "    server.sendmail(sender_email, receiver_email, message.as_string())\n",
    "\n",
    "    # Close the server connection\n",
    "    server.quit()\n",
    "\n",
    "def perform_ocr(image_path):\n",
    "    # Use pytesseract to perform OCR on the image\n",
    "    text_content = pytesseract.image_to_string(Image.open(image_path))\n",
    "    return text_content\n",
    "\n",
    "\n",
    "def display_captured_image(image_path, text_content):\n",
    "    # Display the captured image in a new window\n",
    "    captured_image = Image.open(image_path)\n",
    "    captured_image = captured_image.resize((300, 300), Image.LANCZOS)\n",
    "    photo = ImageTk.PhotoImage(captured_image)\n",
    "\n",
    "    image_window = tk.Toplevel(root)\n",
    "    image_label = tk.Label(image_window, image=photo)\n",
    "    image_label.photo = photo\n",
    "    image_label.pack()\n",
    "    if(text_content):\n",
    "        # Convert the description to audio\n",
    "        text_to_speech = f\"{text_content}\"\n",
    "        tts = gTTS(text=text_to_speech, lang='en')\n",
    "\n",
    "        # Convert the result to audio\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "        # Save the audio file\n",
    "        audio_path = f\"ocr_output_{timestamp}.mp3\"\n",
    "        tts.save(audio_path)\n",
    "\n",
    "        # Play the audio\n",
    "        pygame.mixer.music.load(audio_path)\n",
    "        pygame.mixer.music.play()\n",
    "        # Display the extracted text content\n",
    "        text_label = tk.Label(image_window, text=text_content, wraplength=300)\n",
    "        text_label.pack()\n",
    "\n",
    "def generate_emergency_message():\n",
    "    # Get current location details\n",
    "    location = get_current_location()\n",
    "    \n",
    "    # Get current timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Generate emergency message\n",
    "    emergency_message = f\"aiCanSEE App: Emergency! Need help! Location is: {location}. Time of message: {timestamp}\"\n",
    "   \n",
    "    return emergency_message\n",
    "\n",
    "def send_whatsapp_message(phone_number, message):\n",
    "    # Format the phone number (remove non-numeric characters)\n",
    "    formatted_phone_number = ''.join(c for c in phone_number if c.isdigit())\n",
    "\n",
    "    # Create the WhatsApp message link\n",
    "    whatsapp_link = f\"https://wa.me/{formatted_phone_number}?text={message}\"\n",
    "\n",
    "    # Open the link or display it for the user to click\n",
    "    webbrowser.open(whatsapp_link)\n",
    "\n",
    "def send_emergency_message():\n",
    "    emergency_message = generate_emergency_message()\n",
    "    # Display the emergency message in the app\n",
    "    phone_number = \"type a number here\"  # emergency contact number\n",
    "    send_whatsapp_message(phone_number, emergency_message)\n",
    "\n",
    "def find_dominant_color(image_path, k=1):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    # Convert image pixels to a flat array of BGR values\n",
    "    pixels = image.reshape((-1, 3))\n",
    "    \n",
    "    # Convert to float for more accurate k-means prediction\n",
    "    pixels = np.float32(pixels)\n",
    "    \n",
    "    # Use k-means clustering to find most dominant color(s)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    _, labels, centers = cv2.kmeans(pixels, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    \n",
    "    # Convert centers to integers (BGR values)\n",
    "    centers = np.uint8(centers)\n",
    "    \n",
    "    # Get the most dominant color\n",
    "    dominant_color = centers[0].tolist()\n",
    "    \n",
    "    return dominant_color\n",
    "\n",
    "\n",
    "def describe_color(rgb_values):\n",
    "\n",
    "    base_url = \"https://www.thecolorapi.com/id\"\n",
    "    # Construct the URL with RGB values\n",
    "    url = f\"{base_url}?rgb={','.join(map(str, rgb_values))}&format=json\"\n",
    "\n",
    "    # Make the GET request\n",
    "    response = requests.get(url)\n",
    "    color_data = response.json()\n",
    "    color_name = color_data[\"name\"][\"value\"]\n",
    "    return f\"The color is {color_name}.\"\n",
    "\n",
    "def capture_and_analyze_color():\n",
    "    \n",
    "    image_path = capture_image(1)\n",
    "    \n",
    "    # Find dominant color\n",
    "    dominant_color = find_dominant_color(image_path, k=1)\n",
    "    \n",
    "    # Convert BGR to RGB\n",
    "    dominant_color_rgb = dominant_color[::-1]\n",
    "    \n",
    "    print(f\"Dominant Color (RGB): {dominant_color_rgb}\")\n",
    "    color_description = describe_color(dominant_color_rgb)\n",
    "    print(color_description)\n",
    "    # Convert the result to audio\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    # Convert the color description to audio\n",
    "    output_path = f\"color_description_{timestamp}.mp3\"\n",
    "    text_to_speech(color_description, output_path)\n",
    "    playaudio(output_path)\n",
    "\n",
    "def load_image(image_path):\n",
    "    img = Image.open(image_path).resize((224, 224))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "    return img_array / 255.0 \n",
    "def predict_description(image_path):\n",
    "    model_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n",
    "    model = hub.load(model_url)\n",
    "    image = load_image(image_path)\n",
    "    predictions = model(image)\n",
    "    class_id = tf.argmax(predictions[0]).numpy()\n",
    "    labels_path = tf.keras.utils.get_file('ImageNetLabels.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
    "    with open(labels_path) as f:\n",
    "        labels = f.read().splitlines()\n",
    "    object = labels[class_id]\n",
    "    return object\n",
    "\n",
    "def evaluate():\n",
    "    # Capture image (assuming you have a capture_image function)\n",
    "    image_path = capture_image(1)\n",
    "\n",
    "    # Get textual description from the model\n",
    "    description = predict_description(image_path)\n",
    "    print(description)\n",
    "\n",
    "    # Convert the description to audio\n",
    "    text_to_speech = f\"It might be  {description}\"\n",
    "    tts = gTTS(text=text_to_speech, lang='en')\n",
    "\n",
    "    # Convert the result to audio\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    # Save the audio file\n",
    "    audio_path = f\"output_{timestamp}.mp3\"\n",
    "    tts.save(audio_path)\n",
    "\n",
    "    # Play the audio\n",
    "    pygame.mixer.music.load(audio_path)\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "# Your email credentials\n",
    "sender_email = \"sender@gmail.com\"\n",
    "sender_password = \"password\"\n",
    "receiver_email = \"receiver@gmail.com\"\n",
    "\n",
    "# Global counters for taps\n",
    "capture_tap_count = 0\n",
    "alarm_tap_count = 0\n",
    "\n",
    "# Capture Image Tap Handler\n",
    "def handle_capture_tap():\n",
    "    global capture_tap_count\n",
    "    capture_tap_count += 1\n",
    "    if capture_tap_count == 2:\n",
    "        # Execute capture image function\n",
    "        capture_image(2)\n",
    "        capture_tap_count = 0  # Reset tap count\n",
    "\n",
    "# Alarm Tap Handler\n",
    "def handle_alarm_tap():\n",
    "    global alarm_tap_count\n",
    "    alarm_tap_count += 1\n",
    "    if alarm_tap_count == 3:\n",
    "        # Execute play alarm sound function\n",
    "        play_alarm_sound()\n",
    "        alarm_tap_count = 0  # Reset tap count\n",
    "# Tkinter setup\n",
    "root = tk.Tk()\n",
    "root.title(\"aICanSEE\")\n",
    "\n",
    "# Button to execute the weather suggestion\n",
    "execute_button = tk.Button(root, text=\"1. Weather\", command=execute_suggestion, height=5, width=20)\n",
    "execute_button.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "# Button for capturing an image, configured for double tap\n",
    "capture_button = tk.Button(root, text=\"2. Capture and Send(Tap 2)\", command=handle_capture_tap, height=5, width=20)\n",
    "capture_button.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "analyze_color_button = tk.Button(root, text=\"3. Find Color\", command=capture_and_analyze_color, height=5, width=20)\n",
    "analyze_color_button.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "# Button to send emergency message\n",
    "help_button = tk.Button(root, text=\"4. Help Me\", command=send_emergency_message, height=5, width=20)\n",
    "help_button.grid(row=1, column=1, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "# Button to execute the evaluation\n",
    "eval_button = tk.Button(root,text=\"5. Tell me the object?\",command=evaluate, height=5, width=20)\n",
    "eval_button.grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "# Button for triggering an alarm, configured for triple tap\n",
    "alarm_button = tk.Button(root, text=\"6. Emergency Alarm (Tap 3)\", command=handle_alarm_tap, height=5, width=20)\n",
    "alarm_button.grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
